<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="{{url_for('static',filename='./css/main.css')}}">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" />
    <title>Toxic Classifier</title>
</head>

<body>

    <div class="NavBar">
        <div class="home">
            <a href="#Description">
                <span class="material-symbols-outlined">
                home
                </span>
            </a>

        </div>

        <div class="TitleText">
            Toxicity Classifier
        </div>

        <div class="classify">
            <span class="material-symbols-outlined">
                search
                </span>

        </div>
    </div>

    <div name="mainBody" class="mainBody">
        <div class="mainContent">
            <span name="Description">In this application we will classify the Various Texts and provide a toxicity report for each of them.
                <br>

                With an increase in the need of online communication, multiple websites and applications have integrated an in-application messaging option. It is a very convenient and useful feature but it is also important to discourage any toxicity.
                Our aim is to make a toxicity detection module which can predict the amount of toxicity in a particular text. This module can help identify any toxic texts or even people which can then be reported to the authorities.


            </span>

        </div>
    </div>

</body>

</html>